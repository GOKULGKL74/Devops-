IAAS -by Terraform/ CFT 

Terraform:
-write
-plan -b4 execution dry run (test)
-Apply

1.configure aws with cli [aws->security cred ->id]
2.create .tf file
3.run main.tf file  ->creates teraform.tfstate   //tracking

vm.outputfiles  -user to knw which shold be shown on output log(eg:no access o aws how to check ip -by running pipleine /run we will c logs there we  get ip so on..] 
vm.inputfiles- variables
statefile
  always in centralized loacation-s3 -should be read access [bz file stored in gitnub some one clone and proceed chnges and lokks dif in statefile 
github  statefie != our state file not possible so centralised loc
  dont store it in local


....
STEP1: terraform init,plan,deploy,destroy

practise:

user---jenkins(execute the tf) ---github(stored tf file)-aws
                                  |
                                statefile -stored in s3 -dynamo db(locking purpose to avoid conflict/parallel execution)


......................................................
resources -aws,azurerm,..

Variables: inp,out
  inp -pass info to terraform
  out -console to print 

eg:
variable "instance_type"{
type:string
default:"t2.micro"
}

resource "instance" "ins"{
 instance_type=var.instance_type
}

structure:
variable.tf
provider.tf ....so on

terraform.tfvar  ->input dynamically
.................................................................................
2.variables:
-->string
-->number
-->bool
-->list    /type list(string)  default =[,,]   -eg:iam user
-->map     /type map(string)        eg:tags

variable "ec2" {
  description=""
  type=string    //mandatry
  default= "t2.micro"   //value
}
variable "ec2_count" {
  description=""
  type=number    //mandatry
  default= 2   //value
}

resource "aws_instance" "name"{
    ami= ""
    instance_type=var.ec2
    count=var.ec2_count
}

type=string  -->alue
type=number  -->no of isntance 
........................................................................................

          Multiple terraform.tfvars
main. tf        vaiable.tf      stage.tfvars      production.tfvars

terraform apply -varofile=" "

......................................................
command line arg

  terraform apply var="instance_type=t2.micro"

.......................................................
local variable

locals{
  var="staging"
}

${local.var}
..........................
output values:

output "vaalue"

{
  value=aws_instance.name.public_ip
}

/.............
loop
count -list
for_each -set/map

............
statefiles: every command update the value what we are doing in tfstate file.
  it creted by default when apply command used

statefile store it in s3
    terraform
    {
      backend "s3"
      {
        bucket="name"
        key ="key/terraform.tfstate"         //folder
        region=""
      }
    }

  terraform state pull -if u r abesence u dont knw wat action performed on that directry
                        while using that cmd u will get hstry**

  terraform state push -update the state file //dangerous dont use //overide

.................................
Terraform Provisioners
    helps to move file from source to destination

  provisioner "name"
  {
    source ="//path"
    destination=""
  }

local provisioner -after apply it will create file 
remote exec 

provisioner "remote-exec"
  {
    inline =[
    "touch hello.txt",
    "echo helooo >> hello.txt",
    ]
  }
............................................
modules:

